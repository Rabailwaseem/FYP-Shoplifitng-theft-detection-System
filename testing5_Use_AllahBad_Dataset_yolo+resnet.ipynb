{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfifaMasood/AfifaMasood/blob/main/testing5_Use_AllahBad_Dataset_yolo%2Bresnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRREHEgDazgz",
        "outputId": "57bc4018-3fc5-4f29-a723-8fef95200aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics pandas opencv-python deep_sort_realtime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iUA--GIa0je",
        "outputId": "e36e22fd-366c-4a93-b330-bba45713f9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.130-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting deep_sort_realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.130-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, deep_sort_realtime, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deep_sort_realtime-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.130 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Constants\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 256, 256\n",
        "CLASSES_LIST = [\"Normal\", \"Shoplifting\"]\n",
        "HEIGHT_THRESHOLD = 250  # Minimum height for processing a person\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    return resized_frame / 255.0\n",
        "\n",
        "# Load frame-level model (TensorFlow)\n",
        "frame_model = tf.keras.models.load_model('/content/drive/MyDrive/60_model_bs_256_frame2.h5')\n",
        "\n",
        "def is_clear_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    mean_intensity = np.mean(gray)\n",
        "\n",
        "    sharpness_threshold = 50\n",
        "    brightness_threshold = 40\n",
        "\n",
        "    return laplacian_var > sharpness_threshold and mean_intensity > brightness_threshold\n",
        "\n",
        "def process_video(video_path, output_video_path):\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    frame_rate = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    width, height = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
        "\n",
        "    yolov8_model = YOLO(\"yolov8n.pt\")\n",
        "    resnet_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "    num_ftrs = resnet_model.fc.in_features\n",
        "    resnet_model.fc = nn.Linear(num_ftrs, 2)\n",
        "    resnet_model.load_state_dict(torch.load(\"/content/drive/MyDrive/resnet34_shoplifting.pth\"))\n",
        "    resnet_model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    resnet_model.to(device)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Frame-level prediction\n",
        "        processed_frame = preprocess_frame(frame)\n",
        "        input_data = np.expand_dims(processed_frame, axis=0)\n",
        "        predictions = frame_model.predict(input_data, verbose=0)[0]\n",
        "        normal_probability = predictions[0]\n",
        "        shoplifting_probability = predictions[1]\n",
        "\n",
        "\n",
        "         # Round probabilities to 2 decimal places\n",
        "        normal_probability = round(normal_probability, 2)\n",
        "        shoplifting_probability = round(shoplifting_probability, 2)\n",
        "\n",
        "        # Check if both probabilities are equal (0.50) or shoplifting_probability >= 0.50\n",
        "        if normal_probability == shoplifting_probability or shoplifting_probability >= 0.50:\n",
        "          predicted_class = 1  # Force prediction to \"Shoplifting\"\n",
        "        else:\n",
        "           predicted_class = np.argmax(predictions)\n",
        "\n",
        "        predicted_label = CLASSES_LIST[predicted_class]\n",
        "        predicted_prob = max(normal_probability, shoplifting_probability)\n",
        "\n",
        "        # Draw frame-level prediction text\n",
        "        text = f\"Prediction: {predicted_label} ({predictions[1]:.2f})\"\n",
        "        cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        results = yolov8_model(frame)\n",
        "\n",
        "        persons = []\n",
        "        for box, cls in zip(results[0].boxes.xyxy, results[0].boxes.cls):\n",
        "            if int(cls) == 0:  # Only process persons\n",
        "                x1, y1, x2, y2 = map(int, box.cpu().numpy())\n",
        "                height = y2 - y1\n",
        "                if height > HEIGHT_THRESHOLD:\n",
        "                    persons.append((height, x1, y1, x2, y2))\n",
        "\n",
        "        if predicted_label == \"Normal\":\n",
        "            # Draw green bounding boxes for all persons and continue\n",
        "            for _, x1, y1, x2, y2 in persons:\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, \"Normal\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        else:\n",
        "            if persons:\n",
        "                # Select the closest person (highest bounding box)\n",
        "                closest_person = max(persons, key=lambda p: p[0])\n",
        "                _, x1, y1, x2, y2 = closest_person\n",
        "\n",
        "                person_image = frame[y1:y2, x1:x2]\n",
        "                if is_clear_image(person_image):\n",
        "                    person_image = cv2.cvtColor(person_image, cv2.COLOR_BGR2RGB)\n",
        "                    pil_image = Image.fromarray(person_image)\n",
        "                    person_image = transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        output = resnet_model(person_image)\n",
        "                        _, predicted = torch.max(output, 1)\n",
        "                        person_label = \"Shoplifting\" if predicted.item() == 1 else \"Normal\"\n",
        "                        color = (0, 0, 255) if person_label == \"Shoplifting\" else (0, 255, 0)\n",
        "\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                    cv2.putText(frame, person_label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "          # ✅ Rotate frame if video was upside-down\n",
        "        frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    video_capture.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"Processing complete. Output saved as {output_video_path}\")\n",
        "\n",
        "# ✅ Call the function correctly\n",
        "process_video(\n",
        "    \"/content/drive/MyDrive/FYP-Dataset-AllahBad/Shoplifting/Shoplifting-134.mp4\",\n",
        "    \"/content/drive/MyDrive/bounding_box_folder_AllahBad/Shoplifting-134_output_video3.mp4\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35URQP84hQZF",
        "outputId": "67f19290-9a19-443b-8c6b-70b2f89b8b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 1 chair, 126.8ms\n",
            "Speed: 5.5ms preprocess, 126.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 123.2ms\n",
            "Speed: 4.7ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 122.4ms\n",
            "Speed: 3.1ms preprocess, 122.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 132.9ms\n",
            "Speed: 3.8ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.7ms\n",
            "Speed: 2.8ms preprocess, 121.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.2ms\n",
            "Speed: 3.8ms preprocess, 121.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 113.6ms\n",
            "Speed: 3.2ms preprocess, 113.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 118.9ms\n",
            "Speed: 2.8ms preprocess, 118.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 113.7ms\n",
            "Speed: 2.7ms preprocess, 113.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 chairs, 126.5ms\n",
            "Speed: 2.8ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.2ms\n",
            "Speed: 2.9ms preprocess, 121.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 120.4ms\n",
            "Speed: 2.6ms preprocess, 120.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.7ms\n",
            "Speed: 3.2ms preprocess, 121.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 chair, 122.2ms\n",
            "Speed: 3.1ms preprocess, 122.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 139.1ms\n",
            "Speed: 2.9ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 126.3ms\n",
            "Speed: 3.4ms preprocess, 126.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 128.3ms\n",
            "Speed: 3.4ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.8ms\n",
            "Speed: 3.1ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 123.0ms\n",
            "Speed: 3.1ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 130.1ms\n",
            "Speed: 3.1ms preprocess, 130.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 125.7ms\n",
            "Speed: 2.6ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 137.4ms\n",
            "Speed: 3.8ms preprocess, 137.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 122.6ms\n",
            "Speed: 3.1ms preprocess, 122.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.6ms\n",
            "Speed: 3.7ms preprocess, 121.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 166.2ms\n",
            "Speed: 2.9ms preprocess, 166.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 188.5ms\n",
            "Speed: 2.9ms preprocess, 188.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 199.6ms\n",
            "Speed: 3.2ms preprocess, 199.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 203.9ms\n",
            "Speed: 2.7ms preprocess, 203.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 199.1ms\n",
            "Speed: 2.8ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 191.7ms\n",
            "Speed: 2.9ms preprocess, 191.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 200.8ms\n",
            "Speed: 3.4ms preprocess, 200.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 211.1ms\n",
            "Speed: 4.8ms preprocess, 211.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 130.6ms\n",
            "Speed: 3.5ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 127.9ms\n",
            "Speed: 3.7ms preprocess, 127.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.5ms\n",
            "Speed: 3.1ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 125.1ms\n",
            "Speed: 3.5ms preprocess, 125.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 chair, 123.7ms\n",
            "Speed: 2.9ms preprocess, 123.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 144.1ms\n",
            "Speed: 2.9ms preprocess, 144.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.6ms\n",
            "Speed: 2.9ms preprocess, 124.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 chair, 123.7ms\n",
            "Speed: 3.3ms preprocess, 123.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.4ms\n",
            "Speed: 4.0ms preprocess, 124.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 128.6ms\n",
            "Speed: 3.2ms preprocess, 128.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.1ms\n",
            "Speed: 3.7ms preprocess, 124.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 123.5ms\n",
            "Speed: 3.3ms preprocess, 123.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 135.4ms\n",
            "Speed: 3.6ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 123.4ms\n",
            "Speed: 3.5ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 126.2ms\n",
            "Speed: 3.3ms preprocess, 126.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.3ms\n",
            "Speed: 3.0ms preprocess, 124.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 124.0ms\n",
            "Speed: 3.5ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 130.2ms\n",
            "Speed: 3.2ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 123.3ms\n",
            "Speed: 3.4ms preprocess, 123.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 140.0ms\n",
            "Speed: 3.4ms preprocess, 140.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 120.6ms\n",
            "Speed: 2.8ms preprocess, 120.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 122.8ms\n",
            "Speed: 3.0ms preprocess, 122.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 121.4ms\n",
            "Speed: 2.7ms preprocess, 121.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 145.1ms\n",
            "Speed: 3.3ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 129.9ms\n",
            "Speed: 3.5ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 125.0ms\n",
            "Speed: 3.5ms preprocess, 125.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 134.2ms\n",
            "Speed: 2.8ms preprocess, 134.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 131.2ms\n",
            "Speed: 5.6ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 120.9ms\n",
            "Speed: 3.3ms preprocess, 120.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 119.4ms\n",
            "Speed: 3.0ms preprocess, 119.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 120.7ms\n",
            "Speed: 3.7ms preprocess, 120.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 121.2ms\n",
            "Speed: 3.2ms preprocess, 121.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 116.5ms\n",
            "Speed: 2.7ms preprocess, 116.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing complete. Output saved as /content/drive/MyDrive/bounding_box_folder_AllahBad/Shoplifting-134_output_video3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO4d4O9MXrKS",
        "outputId": "e78fb2de-21ff-4baa-9bf6-a2d3893620fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Constants\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 256, 256\n",
        "CLASSES_LIST = [\"Normal\", \"Shoplifting\"]\n",
        "HEIGHT_THRESHOLD = 250  # Minimum height for processing a person\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    return resized_frame / 255.0\n",
        "\n",
        "# Load frame-level model (TensorFlow)\n",
        "frame_model = tf.keras.models.load_model('/content/drive/MyDrive/60_model_bs_256_frame2.h5')\n",
        "\n",
        "def get_rotation_angle(video_path):\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\", \"-select_streams\", \"v:0\",\n",
        "            \"-show_entries\", \"stream_tags=rotate\", \"-of\", \"json\", video_path\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        ffprobe_output = json.loads(result.stdout)\n",
        "        rotation = int(ffprobe_output[\"streams\"][0][\"tags\"].get(\"rotate\", 0))\n",
        "        return rotation\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine rotation: {e}\")\n",
        "        return 0  # Assume no rotation if error\n",
        "\n",
        "def is_clear_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    mean_intensity = np.mean(gray)\n",
        "    return laplacian_var > 50 and mean_intensity > 40\n",
        "\n",
        "def process_video(video_path, output_video_path):\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    frame_rate = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
        "\n",
        "    # Check if video needs rotation using ffprobe\n",
        "    rotation_angle = get_rotation_angle(video_path)\n",
        "    rotate_required = (rotation_angle == 180)\n",
        "\n",
        "    # Load YOLOv8 and ResNet34\n",
        "    yolov8_model = YOLO(\"yolov8n.pt\")\n",
        "    resnet_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "    num_ftrs = resnet_model.fc.in_features\n",
        "    resnet_model.fc = nn.Linear(num_ftrs, 2)\n",
        "    resnet_model.load_state_dict(torch.load(\"/content/drive/MyDrive/resnet34_shoplifting.pth\"))\n",
        "    resnet_model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    resnet_model.to(device)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed_frame = preprocess_frame(frame)\n",
        "        input_data = np.expand_dims(processed_frame, axis=0)\n",
        "        predictions = frame_model.predict(input_data, verbose=0)[0]\n",
        "        normal_probability = round(predictions[0], 2)\n",
        "        shoplifting_probability = round(predictions[1], 2)\n",
        "\n",
        "        if normal_probability == shoplifting_probability or shoplifting_probability >= 0.50:\n",
        "            predicted_class = 1\n",
        "        else:\n",
        "            predicted_class = np.argmax(predictions)\n",
        "\n",
        "        predicted_label = CLASSES_LIST[predicted_class]\n",
        "        text = f\"Prediction: {predicted_label} ({predictions[1]:.2f})\"\n",
        "        cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        results = yolov8_model(frame)\n",
        "        persons = []\n",
        "        for box, cls in zip(results[0].boxes.xyxy, results[0].boxes.cls):\n",
        "            if int(cls) == 0:\n",
        "                x1, y1, x2, y2 = map(int, box.cpu().numpy())\n",
        "                height = y2 - y1\n",
        "                if height > HEIGHT_THRESHOLD:\n",
        "                    persons.append((height, x1, y1, x2, y2))\n",
        "\n",
        "        box_color = (0, 0, 255) if predicted_label == \"Shoplifting\" else (0, 255, 0)\n",
        "\n",
        "        for _, x1, y1, x2, y2 in persons:\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
        "\n",
        "        # Rotate if needed\n",
        "        if rotate_required:\n",
        "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
        "\n",
        "        # Slow down for shoplifting\n",
        "        repeat_count = 5 if predicted_label == \"Shoplifting\" else 1\n",
        "        for _ in range(repeat_count):\n",
        "            out.write(frame)\n",
        "\n",
        "    video_capture.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"✅ Processing complete. Output saved as {output_video_path}\")\n",
        "\n",
        "# ✅ Call the function\n",
        "process_video(\n",
        "    \"/content/drive/MyDrive/FYP-Dataset-AllahBad/Shoplifting/Shoplifting-309.mp4\",\n",
        "    \"/content/drive/MyDrive/bounding_box_folder_AllahBad/pre_Shoplifting-309_output_video.mp4\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_rvKB4zJO-7",
        "outputId": "49c6488b-9189-43ed-8b05-12627156823c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 2 bottles, 137.1ms\n",
            "Speed: 4.0ms preprocess, 137.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 127.3ms\n",
            "Speed: 4.5ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 122.4ms\n",
            "Speed: 4.2ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 135.5ms\n",
            "Speed: 4.2ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 122.2ms\n",
            "Speed: 3.6ms preprocess, 122.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 123.1ms\n",
            "Speed: 4.5ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 123.7ms\n",
            "Speed: 3.9ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 121.1ms\n",
            "Speed: 3.7ms preprocess, 121.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 126.9ms\n",
            "Speed: 3.9ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 bottle, 120.3ms\n",
            "Speed: 4.2ms preprocess, 120.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 122.4ms\n",
            "Speed: 4.2ms preprocess, 122.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 120.8ms\n",
            "Speed: 4.1ms preprocess, 120.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 121.9ms\n",
            "Speed: 3.9ms preprocess, 121.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 126.6ms\n",
            "Speed: 4.0ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 135.3ms\n",
            "Speed: 3.7ms preprocess, 135.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 motorcycle, 127.5ms\n",
            "Speed: 3.8ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 122.2ms\n",
            "Speed: 3.6ms preprocess, 122.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 121.3ms\n",
            "Speed: 3.9ms preprocess, 121.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 132.2ms\n",
            "Speed: 4.4ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 teddy bear, 132.0ms\n",
            "Speed: 5.1ms preprocess, 132.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 126.4ms\n",
            "Speed: 4.0ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 199.5ms\n",
            "Speed: 3.7ms preprocess, 199.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 190.6ms\n",
            "Speed: 7.4ms preprocess, 190.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 181.6ms\n",
            "Speed: 4.1ms preprocess, 181.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 197.1ms\n",
            "Speed: 3.9ms preprocess, 197.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 188.2ms\n",
            "Speed: 4.4ms preprocess, 188.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 190.9ms\n",
            "Speed: 3.8ms preprocess, 190.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 refrigerator, 197.9ms\n",
            "Speed: 6.4ms preprocess, 197.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 202.7ms\n",
            "Speed: 4.0ms preprocess, 202.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 1 refrigerator, 119.1ms\n",
            "Speed: 4.5ms preprocess, 119.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 1 refrigerator, 121.9ms\n",
            "Speed: 3.9ms preprocess, 121.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 120.0ms\n",
            "Speed: 4.4ms preprocess, 120.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 1 refrigerator, 123.1ms\n",
            "Speed: 6.8ms preprocess, 123.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 1 refrigerator, 127.1ms\n",
            "Speed: 3.7ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 124.1ms\n",
            "Speed: 3.9ms preprocess, 124.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 4 bottles, 144.1ms\n",
            "Speed: 4.1ms preprocess, 144.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 3 bottles, 120.9ms\n",
            "Speed: 4.6ms preprocess, 120.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 126.0ms\n",
            "Speed: 4.0ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 120.8ms\n",
            "Speed: 3.7ms preprocess, 120.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 121.4ms\n",
            "Speed: 4.2ms preprocess, 121.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 120.3ms\n",
            "Speed: 3.9ms preprocess, 120.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 122.4ms\n",
            "Speed: 4.1ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 1 bottle, 1 apple, 122.7ms\n",
            "Speed: 4.1ms preprocess, 122.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 123.4ms\n",
            "Speed: 3.6ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 1 apple, 121.1ms\n",
            "Speed: 4.3ms preprocess, 121.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 3 bottles, 135.5ms\n",
            "Speed: 4.2ms preprocess, 135.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 1 apple, 127.7ms\n",
            "Speed: 3.7ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 125.5ms\n",
            "Speed: 5.4ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 1 apple, 124.4ms\n",
            "Speed: 4.1ms preprocess, 124.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 130.4ms\n",
            "Speed: 6.3ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 1 refrigerator, 122.7ms\n",
            "Speed: 4.4ms preprocess, 122.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 122.0ms\n",
            "Speed: 3.6ms preprocess, 122.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 125.0ms\n",
            "Speed: 4.3ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 125.0ms\n",
            "Speed: 4.5ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 119.5ms\n",
            "Speed: 4.1ms preprocess, 119.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 126.7ms\n",
            "Speed: 4.1ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 136.5ms\n",
            "Speed: 4.4ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 122.3ms\n",
            "Speed: 4.2ms preprocess, 122.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 119.9ms\n",
            "Speed: 4.5ms preprocess, 119.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 120.4ms\n",
            "Speed: 4.2ms preprocess, 120.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 126.4ms\n",
            "Speed: 4.6ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 121.2ms\n",
            "Speed: 4.1ms preprocess, 121.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 127.7ms\n",
            "Speed: 3.8ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 184.0ms\n",
            "Speed: 3.9ms preprocess, 184.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 188.2ms\n",
            "Speed: 6.5ms preprocess, 188.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 192.3ms\n",
            "Speed: 3.7ms preprocess, 192.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 193.4ms\n",
            "Speed: 4.1ms preprocess, 193.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 186.9ms\n",
            "Speed: 4.1ms preprocess, 186.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 motorcycles, 2 bottles, 190.4ms\n",
            "Speed: 3.6ms preprocess, 190.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 1 refrigerator, 1 teddy bear, 194.8ms\n",
            "Speed: 4.2ms preprocess, 194.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 1 teddy bear, 208.6ms\n",
            "Speed: 3.8ms preprocess, 208.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 2 bottles, 124.8ms\n",
            "Speed: 4.2ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 121.3ms\n",
            "Speed: 4.4ms preprocess, 121.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 125.2ms\n",
            "Speed: 4.0ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 refrigerator, 120.7ms\n",
            "Speed: 4.4ms preprocess, 120.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 apple, 1 refrigerator, 122.9ms\n",
            "Speed: 4.5ms preprocess, 122.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 apple, 1 refrigerator, 119.7ms\n",
            "Speed: 3.8ms preprocess, 119.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 3 bottles, 1 apple, 1 refrigerator, 142.1ms\n",
            "Speed: 5.7ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 126.1ms\n",
            "Speed: 4.4ms preprocess, 126.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 apple, 123.6ms\n",
            "Speed: 4.2ms preprocess, 123.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 125.4ms\n",
            "Speed: 3.1ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 1 refrigerator, 122.1ms\n",
            "Speed: 4.1ms preprocess, 122.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 3 bottles, 123.3ms\n",
            "Speed: 4.2ms preprocess, 123.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 121.4ms\n",
            "Speed: 4.4ms preprocess, 121.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 refrigerator, 129.0ms\n",
            "Speed: 3.7ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 refrigerator, 121.4ms\n",
            "Speed: 3.9ms preprocess, 121.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 120.4ms\n",
            "Speed: 3.8ms preprocess, 120.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 124.3ms\n",
            "Speed: 4.4ms preprocess, 124.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 136.6ms\n",
            "Speed: 4.5ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 4 bottles, 125.0ms\n",
            "Speed: 4.1ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 3 bottles, 123.6ms\n",
            "Speed: 4.5ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 125.9ms\n",
            "Speed: 4.8ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 128.0ms\n",
            "Speed: 6.4ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 4 bottles, 124.7ms\n",
            "Speed: 4.8ms preprocess, 124.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 bottles, 123.2ms\n",
            "Speed: 4.4ms preprocess, 123.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 126.8ms\n",
            "Speed: 5.9ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 124.6ms\n",
            "Speed: 3.7ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 4 bottles, 1 refrigerator, 121.4ms\n",
            "Speed: 3.9ms preprocess, 121.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 122.5ms\n",
            "Speed: 4.0ms preprocess, 122.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 134.7ms\n",
            "Speed: 4.7ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 125.6ms\n",
            "Speed: 4.6ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 bottle, 122.5ms\n",
            "Speed: 4.1ms preprocess, 122.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 122.2ms\n",
            "Speed: 4.1ms preprocess, 122.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 1 bowl, 121.1ms\n",
            "Speed: 3.9ms preprocess, 121.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 124.6ms\n",
            "Speed: 4.1ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 bottles, 124.5ms\n",
            "Speed: 4.1ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 bottles, 213.1ms\n",
            "Speed: 4.5ms preprocess, 213.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 4 bottles, 193.1ms\n",
            "Speed: 4.0ms preprocess, 193.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 1 bottle, 218.5ms\n",
            "Speed: 4.1ms preprocess, 218.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 bottles, 192.8ms\n",
            "Speed: 3.8ms preprocess, 192.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processing complete. Output saved as /content/drive/MyDrive/bounding_box_folder_AllahBad/pre_Shoplifting-309_output_video.mp4\n"
          ]
        }
      ]
    }
  ]
}