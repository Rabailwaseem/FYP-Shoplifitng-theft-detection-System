{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfifaMasood/AfifaMasood/blob/main/Copy_of_Resnet%2Bcropped_images%2Byolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUk0d1yrj_n",
        "outputId": "4d551a8a-f36d-4fd3-e7a6-1b1396ef21c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjQEWwMCpD0j",
        "outputId": "e47aad6a-8713-4e11-a7e2-3d45269f628e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading dataset from: /content/drive/MyDrive/split_dataset_3/train\n",
            "‚úÖ Dataset loaded: 21438 images found (Skipped 0 corrupt images)\n",
            "üîÑ Loading dataset from: /content/drive/MyDrive/split_dataset_3/test\n",
            "‚úÖ Dataset loaded: 5000 images found (Skipped 0 corrupt images)\n",
            "üìä Shoplifting count in train: 10719\n",
            "üìä Normal count in train: 10719\n",
            "‚è≥ Loading ResNet34 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ResNet34 model loaded and modified.\n",
            "\n",
            "üöÄ Starting Training...\n",
            "\n",
            "Epoch [1/10], Loss: 0.2284\n",
            "Epoch [2/10], Loss: 0.0815\n",
            "Epoch [3/10], Loss: 0.0598\n",
            "Epoch [4/10], Loss: 0.0515\n",
            "Epoch [5/10], Loss: 0.0417\n",
            "Epoch [6/10], Loss: 0.0752\n",
            "Epoch [7/10], Loss: 0.0394\n",
            "Epoch [8/10], Loss: 0.0273\n",
            "Epoch [9/10], Loss: 0.0291\n",
            "Epoch [10/10], Loss: 0.0251\n",
            "\n",
            "üéâ Training complete. Model saved as 'resnet34_shoplifting.pth' üéâ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Custom Dataset class to extract labels from filenames\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.corrupt_images = []  # Store corrupt image names\n",
        "\n",
        "        print(f\"üîÑ Loading dataset from: {root_dir}\")\n",
        "\n",
        "        # List all the images in the directory\n",
        "        for subdir, _, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".jpg\"):\n",
        "                    file_path = os.path.join(subdir, file)\n",
        "\n",
        "                    # Check if the image is corrupted or empty\n",
        "                    if os.path.getsize(file_path) == 0:  # Zero-byte file check\n",
        "                        print(f\"‚ö†Ô∏è Skipping zero-byte image: {file}\")\n",
        "                        self.corrupt_images.append(file)\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        # Try to open the image to check for corruption\n",
        "                        with Image.open(file_path) as img:\n",
        "                            img.verify()  # Verify image integrity\n",
        "                    except (UnidentifiedImageError, IOError):\n",
        "                        print(f\"‚ö†Ô∏è Corrupt image detected & skipped: {file}\")\n",
        "                        self.corrupt_images.append(file)\n",
        "                        continue  # Skip corrupted images\n",
        "\n",
        "                    # Extract class label from filename (e.g., \"Shoplifting-1_frame0.jpg\")\n",
        "                    label = file.split('-')[0]\n",
        "                    self.image_paths.append(file_path)\n",
        "                    self.labels.append(label)\n",
        "\n",
        "        # Convert labels to indices\n",
        "        self.label_map = {'Shoplifting': 1, 'Normal': 0}\n",
        "        self.labels = [self.label_map.get(label, 0) for label in self.labels]\n",
        "\n",
        "        print(f\"‚úÖ Dataset loaded: {len(self.image_paths)} images found (Skipped {len(self.corrupt_images)} corrupt images)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_paths[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_name).convert(\"RGB\")  # Convert to RGB\n",
        "        except (UnidentifiedImageError, IOError):\n",
        "            print(f\"‚ö†Ô∏è Skipping unreadable image: {img_name}\")\n",
        "            return None, None  # Return None to avoid crashes\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset (already cropped person images)\n",
        "dataset_path = \"/content/drive/MyDrive/split_dataset_3\"\n",
        "\n",
        "train_dataset = CustomDataset(root_dir=dataset_path + \"/train\", transform=transform)\n",
        "test_dataset = CustomDataset(root_dir=dataset_path + \"/test\", transform=transform)\n",
        "\n",
        "# Show the number of images per class in training data\n",
        "train_labels = [label for _, label in train_dataset if label is not None]\n",
        "print(f\"üìä Shoplifting count in train: {train_labels.count(1)}\")\n",
        "print(f\"üìä Normal count in train: {train_labels.count(0)}\")\n",
        "\n",
        "# Filter out None values from the dataset before DataLoader\n",
        "train_dataset.image_paths, train_dataset.labels = zip(\n",
        "    *[(img, lbl) for img, lbl in zip(train_dataset.image_paths, train_dataset.labels) if lbl is not None]\n",
        ")\n",
        "\n",
        "test_dataset.image_paths, test_dataset.labels = zip(\n",
        "    *[(img, lbl) for img, lbl in zip(test_dataset.image_paths, test_dataset.labels) if lbl is not None]\n",
        ")\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Load the pre-trained ResNet50 model and modify it for 2 classes (Shoplifting & Normal)\n",
        "print(\"‚è≥ Loading ResNet34 model...\")\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: Shoplifting, Normal\n",
        "print(\"‚úÖ ResNet34 model loaded and modified.\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nüöÄ Starting Training...\\n\")\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/resnet34_shoplifting.pth\")\n",
        "print(\"\\nüéâ Training complete. Model saved as 'resnet34_shoplifting.pth' üéâ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy checking function\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for x, y in loader:\n",
        "            if x is None or y is None:  # Skip None batches\n",
        "                continue\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item()\n",
        "            num_samples += y.size(0)\n",
        "\n",
        "    accuracy = float(num_correct) / num_samples * 100\n",
        "    return accuracy\n",
        "\n",
        "# Load and check train accuracy\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/resnet34_shoplifting.pth', map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# Train Accuracy\n",
        "print('Train Accuracy:')\n",
        "train_accuracy = check_accuracy(train_loader, model)\n",
        "print(f'Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "# Test Accuracy\n",
        "print('Test Accuracy:')\n",
        "test_accuracy = check_accuracy(test_loader, model)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "8heQ7Zx6xl0C",
        "outputId": "3ced2311-30cd-4468-872e-b729bf58d001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-00081a996726>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/resnet34_shoplifting.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:\n"
          ]
        }
      ]
    }
  ]
}