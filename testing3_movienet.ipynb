{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfifaMasood/AfifaMasood/blob/main/testing3_movienet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cH30FpBq0Fn",
        "outputId": "31e38373-462c-460b-b4c2-ef1c485687da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python # Install the latest version of opencv-python\n",
        "!pip install opencv-python-headless # Install the latest version of opencv-python-headless\n",
        "!pip install  tqdm tf-models-official\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "_OuWOaHLkCaR",
        "outputId": "9b28c7a3-7f60-40da-b412-c54fd11c8667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.11.0.86\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.18.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting Cython (from tf-models-official)\n",
            "  Downloading Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (11.1.0)\n",
            "Collecting ai-edge-litert>=1.0.1 (from tf-models-official)\n",
            "  Downloading ai_edge_litert-1.0.1-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (0.5.0)\n",
            "Collecting google-api-python-client>=1.6.7 (from tf-models-official)\n",
            "  Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (1.6.17)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (1.26.4)\n",
            "Collecting oauth2client (from tf-models-official)\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (5.9.5)\n",
            "Collecting py-cpuinfo>=3.3.0 (from tf-models-official)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting pycocotools (from tf-models-official)\n",
            "  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (4.9.7)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting tensorflow-text~=2.18.0 (from tf-models-official)\n",
            "  Downloading tensorflow_text-2.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow~=2.18.0 (from tf-models-official)\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (2.17.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.20.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.27.0)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.24.1)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (1.70.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow~=2.18.0->tf-models-official)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.18.0->tf-models-official) (0.37.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.16.0 (from tf-models-official)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official) (3.2.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official) (2024.11.6)\n",
            "Collecting tabulate>=0.8.9 (from sacrebleu->tf-models-official)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting colorama (from sacrebleu->tf-models-official)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lxml (from sacrebleu->tf-models-official)\n",
            "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official) (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (8.1.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (19.0.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (1.16.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.18.0->tf-models-official) (0.45.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official) (2024.12.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official) (3.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.26.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official) (5.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official) (3.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow~=2.18.0->tf-models-official) (0.1.2)\n",
            "Downloading tf_models_official-2.18.0-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ai_edge_litert-1.0.1-cp311-cp311-manylinux_2_17_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.7/458.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=785cd08ca2066dc25877ccd791712be7aab5bec048a7830fa4b87c0e439a0881\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: py-cpuinfo, uritemplate, tensorflow-model-optimization, tabulate, portalocker, lxml, Cython, colorama, ai-edge-litert, tensorboard, sacrebleu, oauth2client, seqeval, pycocotools, google-auth-httplib2, tensorflow, google-api-python-client, tf-keras, tensorflow-text, tf-models-official\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.17.0\n",
            "    Uninstalling tensorflow-text-2.17.0:\n",
            "      Successfully uninstalled tensorflow-text-2.17.0\n",
            "Successfully installed Cython-3.0.11 ai-edge-litert-1.0.1 colorama-0.4.6 google-api-python-client-2.160.0 google-auth-httplib2-0.2.0 lxml-5.3.0 oauth2client-4.1.3 portalocker-3.1.1 py-cpuinfo-9.0.0 pycocotools-2.0.8 sacrebleu-2.5.1 seqeval-1.2.2 tabulate-0.9.0 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.18.1 tf-keras-2.18.0 tf-models-official-2.18.0 uritemplate-4.1.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model\n",
        "\n",
        "CLASSES_LIST = [\"Normal\", \"Shoplifting\"]\n",
        "\n",
        "# Number of frames required by the model\n",
        "SEQUENCE_LENGTH = 8\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    frame = cv2.resize(frame, (256, 256))\n",
        "    frame = frame / 255.0  # Normalize\n",
        "    return frame.astype(np.float32)\n",
        "\n",
        "import keras\n",
        "\n",
        "def load_trained_model(model_path):\n",
        "    \"\"\"\n",
        "    Loads the trained MoviNet model from TensorFlow SavedModel format using TFSMLayer.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = keras.layers.TFSMLayer(model_path, call_endpoint=\"serving_default\")\n",
        "        print(\"Model loaded successfully using TFSMLayer!\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def frame_predict(video_path, model, output_video_path):\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not video_capture.isOpened():\n",
        "        print(f\"Error: Unable to open video file at {video_path}\")\n",
        "        return\n",
        "\n",
        "    frame_buffer = []  # Buffer to store 8 frames\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
        "\n",
        "    if not out.isOpened():\n",
        "        print(f\"Error: Unable to open video writer for output video at {output_video_path}\")\n",
        "        return\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            print(\"End of video or no frames to read.\")\n",
        "            break\n",
        "\n",
        "        print(f\"Processing frame {frame_count}\")\n",
        "\n",
        "        # Preprocess the frame\n",
        "        processed_frame = preprocess_frame(frame)\n",
        "        frame_buffer.append(processed_frame)  # Add frame to buffer\n",
        "\n",
        "        # Keep buffer size fixed to 8\n",
        "        if len(frame_buffer) > SEQUENCE_LENGTH:\n",
        "            frame_buffer.pop(0)  # Remove oldest frame\n",
        "\n",
        "        # Predict only when we have 8 frames\n",
        "        if len(frame_buffer) == SEQUENCE_LENGTH:\n",
        "            input_data = np.array(frame_buffer)  # Convert list to NumPy array\n",
        "            input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension: (1, 8, 256, 256, 3)\n",
        "\n",
        "            # Predict using TFSMLayer\n",
        "            predictions = model(input_data)\n",
        "            predictions = list(predictions.values())[0].numpy()\n",
        "\n",
        "\n",
        "            predicted_class = np.argmax(predictions)\n",
        "            predicted_label = CLASSES_LIST[predicted_class]\n",
        "            predicted_prob = max(predictions[0])\n",
        "\n",
        "            print(f\"Predicted: {predicted_label} ({predicted_prob:.2f})\")\n",
        "\n",
        "            # Annotate frame\n",
        "            color = (0, 0, 255) if predicted_label == \"Shoplifting\" else (255, 255, 255)\n",
        "            text = f\"Prediction: {predicted_label} ({predicted_prob:.2f})\"\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 1.5\n",
        "            font_thickness = 2\n",
        "            text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
        "            text_x, text_y = 10, 40\n",
        "\n",
        "            cv2.rectangle(frame, (text_x - 5, text_y - text_size[1] - 5),\n",
        "                          (text_x + text_size[0] + 5, text_y + 5), (0, 0, 0), -1)\n",
        "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), font_thickness)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    video_capture.release()\n",
        "    out.release()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to process a video and save the output.\n",
        "    \"\"\"\n",
        "    video_path = '/content/drive/MyDrive/FYP Dataset/Shoplifting/Shoplifting-54.mp4'\n",
        "    output_folder = '/content/drive/MyDrive/output_folder_new_movienet'\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"Created output folder: {output_folder}\")\n",
        "\n",
        "    output_video_path = os.path.join(output_folder, 'Shoplifting-54_output.mp4')\n",
        "\n",
        "    # Updated Model Path\n",
        "    model_path = \"/content/drive/MyDrive/MOVINET_SHOPLIFTING_CPU_withouth5\"\n",
        "\n",
        "    model = load_trained_model(model_path)\n",
        "    if model:\n",
        "        frame_predict(video_path, model, output_video_path)\n",
        "        print(f\"Output video saved at: {output_video_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "0QPN3Fjdkmls",
        "outputId": "acb892c7-2802-4b2f-cfdd-699b18ee3930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully using TFSMLayer!\n",
            "Processing frame 0\n",
            "Processing frame 1\n",
            "Processing frame 2\n",
            "Processing frame 3\n",
            "Processing frame 4\n",
            "Processing frame 5\n",
            "Processing frame 6\n",
            "Processing frame 7\n",
            "Predicted: Normal (1.31)\n",
            "Processing frame 8\n",
            "Predicted: Normal (1.72)\n",
            "Processing frame 9\n",
            "Predicted: Normal (2.46)\n",
            "Processing frame 10\n",
            "Predicted: Normal (2.55)\n",
            "Processing frame 11\n",
            "Predicted: Normal (1.72)\n",
            "Processing frame 12\n",
            "Predicted: Normal (0.44)\n",
            "Processing frame 13\n",
            "Predicted: Normal (0.11)\n",
            "Processing frame 14\n",
            "Predicted: Normal (1.29)\n",
            "Processing frame 15\n",
            "Predicted: Normal (1.67)\n",
            "Processing frame 16\n",
            "Predicted: Normal (1.35)\n",
            "Processing frame 17\n",
            "Predicted: Normal (1.02)\n",
            "Processing frame 18\n",
            "Predicted: Normal (1.02)\n",
            "Processing frame 19\n",
            "Predicted: Normal (0.69)\n",
            "Processing frame 20\n",
            "Predicted: Normal (1.29)\n",
            "Processing frame 21\n",
            "Predicted: Normal (1.86)\n",
            "Processing frame 22\n",
            "Predicted: Normal (1.56)\n",
            "Processing frame 23\n",
            "Predicted: Normal (1.53)\n",
            "Processing frame 24\n",
            "Predicted: Normal (1.15)\n",
            "Processing frame 25\n",
            "Predicted: Normal (1.08)\n",
            "Processing frame 26\n",
            "Predicted: Normal (1.47)\n",
            "Processing frame 27\n",
            "Predicted: Normal (1.80)\n",
            "Processing frame 28\n",
            "Predicted: Normal (1.10)\n",
            "Processing frame 29\n",
            "Predicted: Normal (0.76)\n",
            "Processing frame 30\n",
            "Predicted: Shoplifting (0.21)\n",
            "Processing frame 31\n",
            "Predicted: Normal (1.32)\n",
            "Processing frame 32\n",
            "Predicted: Normal (1.79)\n",
            "Processing frame 33\n",
            "Predicted: Normal (1.30)\n",
            "Processing frame 34\n",
            "Predicted: Normal (1.32)\n",
            "Processing frame 35\n",
            "Predicted: Normal (0.23)\n",
            "Processing frame 36\n",
            "Predicted: Shoplifting (0.50)\n",
            "Processing frame 37\n",
            "Predicted: Normal (0.75)\n",
            "Processing frame 38\n",
            "Predicted: Normal (0.82)\n",
            "Processing frame 39\n",
            "Predicted: Shoplifting (0.46)\n",
            "Processing frame 40\n",
            "Predicted: Normal (0.12)\n",
            "Processing frame 41\n",
            "Predicted: Normal (0.42)\n",
            "Processing frame 42\n",
            "Predicted: Normal (0.79)\n",
            "Processing frame 43\n",
            "Predicted: Normal (0.79)\n",
            "Processing frame 44\n",
            "Predicted: Shoplifting (0.50)\n",
            "Processing frame 45\n",
            "Predicted: Shoplifting (0.79)\n",
            "Processing frame 46\n",
            "Predicted: Shoplifting (0.49)\n",
            "Processing frame 47\n",
            "Predicted: Shoplifting (0.34)\n",
            "Processing frame 48\n",
            "Predicted: Normal (0.64)\n",
            "Processing frame 49\n",
            "Predicted: Normal (0.92)\n",
            "Processing frame 50\n",
            "Predicted: Normal (2.38)\n",
            "Processing frame 51\n",
            "Predicted: Normal (2.62)\n",
            "Processing frame 52\n",
            "Predicted: Normal (2.82)\n",
            "Processing frame 53\n",
            "Predicted: Normal (1.34)\n",
            "Processing frame 54\n",
            "Predicted: Normal (0.34)\n",
            "Processing frame 55\n",
            "Predicted: Normal (0.12)\n",
            "Processing frame 56\n",
            "Predicted: Shoplifting (0.20)\n",
            "Processing frame 57\n",
            "Predicted: Normal (0.23)\n",
            "Processing frame 58\n",
            "Predicted: Shoplifting (0.44)\n",
            "Processing frame 59\n",
            "Predicted: Shoplifting (0.80)\n",
            "Processing frame 60\n",
            "Predicted: Normal (0.32)\n",
            "Processing frame 61\n",
            "Predicted: Normal (0.85)\n",
            "Processing frame 62\n",
            "Predicted: Normal (1.38)\n",
            "Processing frame 63\n",
            "Predicted: Normal (0.91)\n",
            "Processing frame 64\n",
            "Predicted: Normal (0.99)\n",
            "Processing frame 65\n",
            "Predicted: Normal (0.62)\n",
            "Processing frame 66\n",
            "Predicted: Shoplifting (1.30)\n",
            "Processing frame 67\n",
            "Predicted: Shoplifting (1.30)\n",
            "Processing frame 68\n",
            "Predicted: Normal (0.34)\n",
            "Processing frame 69\n",
            "Predicted: Normal (0.40)\n",
            "Processing frame 70\n",
            "Predicted: Normal (0.19)\n",
            "Processing frame 71\n",
            "Predicted: Normal (0.10)\n",
            "Processing frame 72\n",
            "Predicted: Shoplifting (0.24)\n",
            "Processing frame 73\n",
            "Predicted: Normal (1.02)\n",
            "Processing frame 74\n",
            "Predicted: Normal (1.39)\n",
            "Processing frame 75\n",
            "Predicted: Shoplifting (0.40)\n",
            "Processing frame 76\n",
            "Predicted: Normal (0.57)\n",
            "Processing frame 77\n",
            "Predicted: Normal (0.83)\n",
            "Processing frame 78\n",
            "Predicted: Shoplifting (0.91)\n",
            "Processing frame 79\n",
            "Predicted: Shoplifting (0.14)\n",
            "Processing frame 80\n",
            "Predicted: Normal (0.26)\n",
            "Processing frame 81\n",
            "Predicted: Normal (0.42)\n",
            "Processing frame 82\n",
            "Predicted: Normal (1.70)\n",
            "Processing frame 83\n",
            "Predicted: Normal (0.58)\n",
            "Processing frame 84\n",
            "Predicted: Shoplifting (0.21)\n",
            "Processing frame 85\n",
            "Predicted: Normal (1.25)\n",
            "Processing frame 86\n",
            "Predicted: Normal (1.93)\n",
            "Processing frame 87\n",
            "Predicted: Normal (2.89)\n",
            "Processing frame 88\n",
            "Predicted: Normal (2.64)\n",
            "Processing frame 89\n",
            "Predicted: Normal (1.10)\n",
            "Processing frame 90\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 91\n",
            "Predicted: Normal (2.21)\n",
            "Processing frame 92\n",
            "Predicted: Normal (1.69)\n",
            "Processing frame 93\n",
            "Predicted: Normal (1.07)\n",
            "Processing frame 94\n",
            "Predicted: Normal (1.67)\n",
            "Processing frame 95\n",
            "Predicted: Normal (2.84)\n",
            "Processing frame 96\n",
            "Predicted: Normal (2.99)\n",
            "Processing frame 97\n",
            "Predicted: Normal (1.79)\n",
            "Processing frame 98\n",
            "Predicted: Normal (1.54)\n",
            "Processing frame 99\n",
            "Predicted: Normal (2.13)\n",
            "Processing frame 100\n",
            "Predicted: Normal (2.94)\n",
            "Processing frame 101\n",
            "Predicted: Normal (2.35)\n",
            "Processing frame 102\n",
            "Predicted: Normal (1.42)\n",
            "Processing frame 103\n",
            "Predicted: Normal (1.15)\n",
            "Processing frame 104\n",
            "Predicted: Normal (2.33)\n",
            "Processing frame 105\n",
            "Predicted: Normal (2.52)\n",
            "Processing frame 106\n",
            "Predicted: Normal (2.36)\n",
            "Processing frame 107\n",
            "Predicted: Normal (2.11)\n",
            "Processing frame 108\n",
            "Predicted: Normal (1.83)\n",
            "Processing frame 109\n",
            "Predicted: Normal (1.93)\n",
            "Processing frame 110\n",
            "Predicted: Normal (2.18)\n",
            "Processing frame 111\n",
            "Predicted: Normal (2.24)\n",
            "Processing frame 112\n",
            "Predicted: Normal (2.16)\n",
            "Processing frame 113\n",
            "Predicted: Normal (2.38)\n",
            "Processing frame 114\n",
            "Predicted: Normal (2.57)\n",
            "Processing frame 115\n",
            "Predicted: Normal (2.40)\n",
            "Processing frame 116\n",
            "Predicted: Normal (1.92)\n",
            "Processing frame 117\n",
            "Predicted: Normal (0.99)\n",
            "Processing frame 118\n",
            "Predicted: Normal (2.45)\n",
            "Processing frame 119\n",
            "Predicted: Normal (2.57)\n",
            "Processing frame 120\n",
            "Predicted: Normal (2.36)\n",
            "Processing frame 121\n",
            "Predicted: Normal (1.48)\n",
            "Processing frame 122\n",
            "Predicted: Normal (2.40)\n",
            "Processing frame 123\n",
            "Predicted: Normal (2.63)\n",
            "Processing frame 124\n",
            "Predicted: Normal (2.66)\n",
            "Processing frame 125\n",
            "Predicted: Normal (2.46)\n",
            "Processing frame 126\n",
            "Predicted: Normal (0.69)\n",
            "Processing frame 127\n",
            "Predicted: Normal (1.46)\n",
            "Processing frame 128\n",
            "Predicted: Normal (1.90)\n",
            "Processing frame 129\n",
            "Predicted: Normal (1.95)\n",
            "Processing frame 130\n",
            "Predicted: Normal (1.71)\n",
            "Processing frame 131\n",
            "Predicted: Normal (1.41)\n",
            "Processing frame 132\n",
            "Predicted: Normal (1.71)\n",
            "Processing frame 133\n",
            "Predicted: Normal (2.09)\n",
            "Processing frame 134\n",
            "Predicted: Normal (2.30)\n",
            "Processing frame 135\n",
            "Predicted: Normal (2.05)\n",
            "Processing frame 136\n",
            "Predicted: Normal (1.34)\n",
            "Processing frame 137\n",
            "Predicted: Normal (1.67)\n",
            "Processing frame 138\n",
            "Predicted: Normal (1.29)\n",
            "Processing frame 139\n",
            "Predicted: Normal (1.55)\n",
            "Processing frame 140\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 141\n",
            "Predicted: Normal (1.87)\n",
            "Processing frame 142\n",
            "Predicted: Normal (2.18)\n",
            "Processing frame 143\n",
            "Predicted: Normal (1.57)\n",
            "Processing frame 144\n",
            "Predicted: Normal (0.58)\n",
            "Processing frame 145\n",
            "Predicted: Shoplifting (0.28)\n",
            "Processing frame 146\n",
            "Predicted: Normal (0.81)\n",
            "Processing frame 147\n",
            "Predicted: Normal (1.48)\n",
            "Processing frame 148\n",
            "Predicted: Normal (1.45)\n",
            "Processing frame 149\n",
            "Predicted: Normal (1.09)\n",
            "Processing frame 150\n",
            "Predicted: Normal (0.89)\n",
            "Processing frame 151\n",
            "Predicted: Normal (1.88)\n",
            "Processing frame 152\n",
            "Predicted: Normal (1.29)\n",
            "Processing frame 153\n",
            "Predicted: Normal (1.11)\n",
            "Processing frame 154\n",
            "Predicted: Normal (1.80)\n",
            "Processing frame 155\n",
            "Predicted: Normal (1.24)\n",
            "Processing frame 156\n",
            "Predicted: Normal (1.94)\n",
            "Processing frame 157\n",
            "Predicted: Normal (1.18)\n",
            "Processing frame 158\n",
            "Predicted: Normal (0.51)\n",
            "Processing frame 159\n",
            "Predicted: Normal (2.23)\n",
            "Processing frame 160\n",
            "Predicted: Normal (2.88)\n",
            "Processing frame 161\n",
            "Predicted: Shoplifting (0.19)\n",
            "Processing frame 162\n",
            "Predicted: Normal (0.15)\n",
            "Processing frame 163\n",
            "Predicted: Normal (1.10)\n",
            "Processing frame 164\n",
            "Predicted: Normal (1.86)\n",
            "Processing frame 165\n",
            "Predicted: Normal (2.81)\n",
            "Processing frame 166\n",
            "Predicted: Normal (2.68)\n",
            "Processing frame 167\n",
            "Predicted: Normal (1.60)\n",
            "Processing frame 168\n",
            "Predicted: Normal (1.31)\n",
            "Processing frame 169\n",
            "Predicted: Normal (1.63)\n",
            "Processing frame 170\n",
            "Predicted: Normal (1.42)\n",
            "Processing frame 171\n",
            "Predicted: Normal (1.49)\n",
            "Processing frame 172\n",
            "Predicted: Normal (1.53)\n",
            "Processing frame 173\n",
            "Predicted: Normal (1.48)\n",
            "Processing frame 174\n",
            "Predicted: Shoplifting (0.64)\n",
            "Processing frame 175\n",
            "Predicted: Shoplifting (0.51)\n",
            "Processing frame 176\n",
            "Predicted: Shoplifting (2.27)\n",
            "Processing frame 177\n",
            "Predicted: Shoplifting (2.00)\n",
            "Processing frame 178\n",
            "Predicted: Shoplifting (1.75)\n",
            "Processing frame 179\n",
            "Predicted: Shoplifting (1.64)\n",
            "Processing frame 180\n",
            "Predicted: Shoplifting (1.76)\n",
            "Processing frame 181\n",
            "Predicted: Shoplifting (2.12)\n",
            "Processing frame 182\n",
            "Predicted: Shoplifting (1.01)\n",
            "Processing frame 183\n",
            "Predicted: Shoplifting (0.16)\n",
            "Processing frame 184\n",
            "Predicted: Shoplifting (-0.00)\n",
            "Processing frame 185\n",
            "Predicted: Normal (0.29)\n",
            "Processing frame 186\n",
            "Predicted: Normal (0.12)\n",
            "Processing frame 187\n",
            "Predicted: Shoplifting (0.61)\n",
            "Processing frame 188\n",
            "Predicted: Normal (1.98)\n",
            "Processing frame 189\n",
            "Predicted: Normal (1.78)\n",
            "Processing frame 190\n",
            "Predicted: Normal (1.91)\n",
            "Processing frame 191\n",
            "Predicted: Normal (2.16)\n",
            "Processing frame 192\n",
            "Predicted: Normal (1.80)\n",
            "Processing frame 193\n",
            "Predicted: Normal (2.04)\n",
            "Processing frame 194\n",
            "Predicted: Normal (1.93)\n",
            "Processing frame 195\n",
            "Predicted: Normal (1.95)\n",
            "Processing frame 196\n",
            "Predicted: Normal (2.14)\n",
            "Processing frame 197\n",
            "Predicted: Normal (2.29)\n",
            "Processing frame 198\n",
            "Predicted: Normal (2.31)\n",
            "Processing frame 199\n",
            "Predicted: Normal (2.30)\n",
            "Processing frame 200\n",
            "Predicted: Normal (2.15)\n",
            "Processing frame 201\n",
            "Predicted: Normal (2.31)\n",
            "Processing frame 202\n",
            "Predicted: Normal (2.17)\n",
            "Processing frame 203\n",
            "Predicted: Normal (2.08)\n",
            "Processing frame 204\n",
            "Predicted: Normal (2.18)\n",
            "Processing frame 205\n",
            "Predicted: Normal (2.00)\n",
            "Processing frame 206\n",
            "Predicted: Normal (1.74)\n",
            "Processing frame 207\n",
            "Predicted: Normal (1.67)\n",
            "Processing frame 208\n",
            "Predicted: Normal (1.39)\n",
            "Processing frame 209\n",
            "Predicted: Normal (1.47)\n",
            "Processing frame 210\n",
            "Predicted: Normal (1.40)\n",
            "Processing frame 211\n",
            "Predicted: Normal (1.74)\n",
            "Processing frame 212\n",
            "Predicted: Normal (1.76)\n",
            "Processing frame 213\n",
            "Predicted: Normal (1.94)\n",
            "Processing frame 214\n",
            "Predicted: Normal (1.85)\n",
            "Processing frame 215\n",
            "Predicted: Normal (1.75)\n",
            "Processing frame 216\n",
            "Predicted: Normal (1.86)\n",
            "Processing frame 217\n",
            "Predicted: Normal (1.73)\n",
            "Processing frame 218\n",
            "Predicted: Normal (1.79)\n",
            "Processing frame 219\n",
            "Predicted: Normal (1.63)\n",
            "Processing frame 220\n",
            "Predicted: Normal (1.62)\n",
            "Processing frame 221\n",
            "Predicted: Normal (1.60)\n",
            "Processing frame 222\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 223\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 224\n",
            "Predicted: Normal (1.62)\n",
            "Processing frame 225\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 226\n",
            "Predicted: Normal (1.66)\n",
            "Processing frame 227\n",
            "Predicted: Normal (1.64)\n",
            "Processing frame 228\n",
            "Predicted: Normal (1.67)\n",
            "Processing frame 229\n",
            "Predicted: Normal (1.65)\n",
            "Processing frame 230\n",
            "Predicted: Normal (1.65)\n",
            "Processing frame 231\n",
            "Predicted: Normal (1.64)\n",
            "Processing frame 232\n",
            "Predicted: Normal (1.64)\n",
            "Processing frame 233\n",
            "Predicted: Normal (1.72)\n",
            "Processing frame 234\n",
            "Predicted: Normal (1.74)\n",
            "Processing frame 235\n",
            "Predicted: Normal (1.70)\n",
            "Processing frame 236\n",
            "Predicted: Normal (1.77)\n",
            "Processing frame 237\n",
            "Predicted: Normal (1.71)\n",
            "Processing frame 238\n",
            "Predicted: Normal (1.73)\n",
            "Processing frame 239\n",
            "Predicted: Normal (1.47)\n",
            "Processing frame 240\n",
            "Predicted: Normal (1.30)\n",
            "Processing frame 241\n",
            "Predicted: Normal (1.16)\n",
            "Processing frame 242\n",
            "Predicted: Normal (1.27)\n",
            "Processing frame 243\n",
            "Predicted: Normal (1.40)\n",
            "Processing frame 244\n",
            "Predicted: Normal (1.13)\n",
            "Processing frame 245\n",
            "Predicted: Normal (1.31)\n",
            "Processing frame 246\n",
            "Predicted: Normal (1.30)\n",
            "Processing frame 247\n",
            "Predicted: Normal (1.26)\n",
            "Processing frame 248\n",
            "Predicted: Normal (1.23)\n",
            "Processing frame 249\n",
            "Predicted: Normal (1.25)\n",
            "Processing frame 250\n",
            "Predicted: Normal (1.39)\n",
            "Processing frame 251\n",
            "Predicted: Normal (1.34)\n",
            "Processing frame 252\n",
            "Predicted: Normal (1.06)\n",
            "Processing frame 253\n",
            "Predicted: Normal (1.12)\n",
            "Processing frame 254\n",
            "Predicted: Normal (1.24)\n",
            "Processing frame 255\n",
            "Predicted: Normal (1.10)\n",
            "Processing frame 256\n",
            "Predicted: Normal (1.28)\n",
            "Processing frame 257\n",
            "Predicted: Normal (1.32)\n",
            "Processing frame 258\n",
            "Predicted: Normal (1.28)\n",
            "Processing frame 259\n",
            "Predicted: Normal (2.22)\n",
            "Processing frame 260\n",
            "Predicted: Normal (2.24)\n",
            "Processing frame 261\n",
            "Predicted: Normal (2.41)\n",
            "Processing frame 262\n",
            "Predicted: Normal (2.98)\n",
            "Processing frame 263\n",
            "Predicted: Normal (2.82)\n",
            "Processing frame 264\n",
            "Predicted: Normal (2.84)\n",
            "Processing frame 265\n",
            "Predicted: Normal (2.69)\n",
            "Processing frame 266\n",
            "Predicted: Normal (2.87)\n",
            "Processing frame 267\n",
            "Predicted: Normal (3.25)\n",
            "Processing frame 268\n",
            "Predicted: Normal (2.59)\n",
            "Processing frame 269\n",
            "Predicted: Normal (1.17)\n",
            "Processing frame 270\n",
            "Predicted: Normal (1.48)\n",
            "Processing frame 271\n",
            "Predicted: Normal (1.81)\n",
            "Processing frame 272\n",
            "Predicted: Normal (1.59)\n",
            "Processing frame 273\n",
            "Predicted: Normal (1.68)\n",
            "Processing frame 274\n",
            "Predicted: Normal (2.03)\n",
            "Processing frame 275\n",
            "Predicted: Normal (2.28)\n",
            "Processing frame 276\n",
            "Predicted: Normal (2.18)\n",
            "Processing frame 277\n",
            "Predicted: Normal (2.14)\n",
            "Processing frame 278\n",
            "Predicted: Normal (1.42)\n",
            "End of video or no frames to read.\n",
            "Output video saved at: /content/drive/MyDrive/output_folder_new_movienet/Shoplifting-54_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model\n",
        "\n",
        "CLASSES_LIST = [\"Normal\", \"Shoplifting\"]\n",
        "SEQUENCE_LENGTH = 3\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    frame = cv2.resize(frame, (256, 256))\n",
        "    frame = frame / 255.0  # Normalize\n",
        "    return frame.astype(np.float32)\n",
        "\n",
        "def load_trained_model(model_path):\n",
        "    try:\n",
        "        model = keras.layers.TFSMLayer(model_path, call_endpoint=\"serving_default\")\n",
        "        print(\"Model loaded successfully using TFSMLayer!\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_video(video_path, model, output_video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "\n",
        "        frame_resized = preprocess_frame(frame)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "        if len(frames) == SEQUENCE_LENGTH:\n",
        "            input_tensor = np.array(frames).reshape(1, SEQUENCE_LENGTH, 256, 256, 3)\n",
        "            prediction = model(input_tensor)\n",
        "\n",
        "            if isinstance(prediction, dict):\n",
        "                prediction = list(prediction.values())[0]  # Extract tensor values\n",
        "\n",
        "            predicted_label = CLASSES_LIST[np.argmax(prediction)]\n",
        "            predicted_prob = np.max(prediction)\n",
        "\n",
        "\n",
        "            print(f\"Predicted: {predicted_label} ({predicted_prob:.2f})\")\n",
        "\n",
        "            # Set color based on prediction\n",
        "            color = (0, 0, 255) if predicted_label == \"Shoplifting\" else (255, 255, 255)\n",
        "            text = f\"Prediction: {predicted_label} ({predicted_prob:.2f})\"\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 1.5\n",
        "            font_thickness = 2\n",
        "            text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
        "            text_x, text_y = 10, 40\n",
        "\n",
        "            cv2.rectangle(frame, (text_x - 5, text_y - text_size[1] - 5),\n",
        "                          (text_x + text_size[0] + 5, text_y + 5), (0, 0, 0), -1)\n",
        "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, color, font_thickness)\n",
        "\n",
        "            frames = []  # Reset frame buffer\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def main():\n",
        "    video_path = '/content/drive/MyDrive/FYP Dataset/Shoplifting/Shoplifting-2.mp4'\n",
        "    output_folder = '/content/drive/MyDrive/output_folder_new_movienet'\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"Created output folder: {output_folder}\")\n",
        "\n",
        "    output_video_path = os.path.join(output_folder, 'Shoplifting-2_output3.mp4')\n",
        "    model_path = \"/content/drive/MyDrive/MOVINET_SHOPLIFTING_CPU_withouth5\"\n",
        "\n",
        "    model = load_trained_model(model_path)\n",
        "    if model:\n",
        "        process_video(video_path, model, output_video_path)\n",
        "        print(f\"Output video saved at: {output_video_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hzWmaIz84nwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}