{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfifaMasood/AfifaMasood/blob/main/Copy_of_Resnet%2Bcropped_images%2Byolo%2Baug_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUk0d1yrj_n",
        "outputId": "ec1981f8-640e-4441-9c9e-f0f630f20ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-6TzT6fqUMn",
        "outputId": "7e98f9fd-9d8a-47c2-a400-8b8501668da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading dataset from: /content/drive/MyDrive/augmented_dataset_17000/train\n",
            "‚úÖ Dataset loaded: 34000 images found (Skipped 0 corrupt images)\n",
            "üîÑ Loading dataset from: /content/drive/MyDrive/augmented_dataset/test\n",
            "‚úÖ Dataset loaded: 5000 images found (Skipped 0 corrupt images)\n",
            "‚è≥ Loading ResNet34 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 89.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ResNet34 model loaded and modified.\n",
            "\n",
            "üöÄ Starting Training...\n",
            "\n",
            "Epoch [1/10], Loss: 0.3483\n",
            "Epoch [2/10], Loss: 0.1464\n",
            "Epoch [3/10], Loss: 0.1093\n",
            "Epoch [4/10], Loss: 0.0765\n",
            "Epoch [5/10], Loss: 0.0611\n",
            "Epoch [6/10], Loss: 0.0569\n",
            "Epoch [7/10], Loss: 0.0549\n",
            "Epoch [8/10], Loss: 0.0482\n",
            "Epoch [9/10], Loss: 0.0371\n",
            "Epoch [10/10], Loss: 0.0343\n",
            "\n",
            "üéâ Training complete. Model saved. üéâ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Custom Dataset class to extract labels from filenames\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, max_shoplifting=None, max_normal=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.corrupt_images = []\n",
        "        shoplifting_count, normal_count = 0, 0\n",
        "\n",
        "        print(f\"üîÑ Loading dataset from: {root_dir}\")\n",
        "\n",
        "        for subdir, _, files in os.walk(root_dir):\n",
        "            for file in sorted(files):\n",
        "                if file.endswith(\".jpg\"):\n",
        "                    file_path = os.path.join(subdir, file)\n",
        "                    if os.path.getsize(file_path) == 0:\n",
        "                        self.corrupt_images.append(file)\n",
        "                        continue\n",
        "                    try:\n",
        "                        with Image.open(file_path) as img:\n",
        "                            img.verify()\n",
        "                    except (UnidentifiedImageError, IOError):\n",
        "                        self.corrupt_images.append(file)\n",
        "                        continue\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    label = None\n",
        "\n",
        "                    if file.startswith(\"Shoplifting_aug_\") or file.startswith(\"Shoplifting-\"):\n",
        "                        label = 'Shoplifting'\n",
        "                        shoplifting_count += 1\n",
        "                    elif file.startswith(\"Normal_aug_\") or file.startswith(\"Normal-\"):\n",
        "                        label = 'Normal'\n",
        "                        normal_count += 1\n",
        "\n",
        "                    if time.time() - start_time > 10:\n",
        "                        print(f\"Skipping {file} due to timeout.\")\n",
        "                        continue\n",
        "\n",
        "                    if label:\n",
        "                        self.image_paths.append(file_path)\n",
        "                        self.labels.append(label)\n",
        "\n",
        "        self.label_map = {'Shoplifting': 1, 'Normal': 0}\n",
        "        self.labels = [self.label_map.get(label, 0) for label in self.labels]\n",
        "\n",
        "        print(f\"‚úÖ Dataset loaded: {len(self.image_paths)} images found (Skipped {len(self.corrupt_images)} corrupt images)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_name).convert(\"RGB\")\n",
        "        except (UnidentifiedImageError, IOError):\n",
        "            return None, None\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define dataset paths separately\n",
        "train_dataset_path = \"/content/drive/MyDrive/augmented_dataset_17000/train\"\n",
        "test_dataset_path = \"/content/drive/MyDrive/augmented_dataset/test\"\n",
        "\n",
        "# Load training dataset with limits\n",
        "train_dataset = CustomDataset(root_dir=train_dataset_path, transform=transform)\n",
        "\n",
        "# Load test dataset with all images (limit set to 5000)\n",
        "test_dataset = CustomDataset(root_dir=test_dataset_path, transform=transform)\n",
        "\n",
        "# Filter None values\n",
        "train_dataset.image_paths, train_dataset.labels = zip(*[(img, lbl) for img, lbl in zip(train_dataset.image_paths, train_dataset.labels) if lbl is not None])\n",
        "test_dataset.image_paths, test_dataset.labels = zip(*[(img, lbl) for img, lbl in zip(test_dataset.image_paths, test_dataset.labels) if lbl is not None])\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Load and modify ResNet34\n",
        "print(\"‚è≥ Loading ResNet34 model...\")\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "print(\"‚úÖ ResNet34 model loaded and modified.\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nüöÄ Starting Training...\\n\")\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "# Save trained model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/resnet34_shoplifting_aug_image1.pth\")\n",
        "print(\"\\nüéâ Training complete. Model saved. üéâ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for x, y in loader:\n",
        "            if x is None or y is None:  # Skip None batches\n",
        "                continue\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item()\n",
        "            num_samples += y.size(0)\n",
        "\n",
        "    accuracy = float(num_correct) / num_samples * 100\n",
        "    return accuracy\n",
        "\n",
        "# Load and check train accuracy\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/resnet34_shoplifting_aug_image1.pth', map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# Train Accuracy\n",
        "print('Train Accuracy:')\n",
        "train_accuracy = check_accuracy(train_loader, model)\n",
        "print(f'Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "# Test Accuracy\n",
        "print('Test Accuracy:')\n",
        "test_accuracy = check_accuracy(test_loader, model)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BK49rOZY0sd",
        "outputId": "bff3983d-9c78-4eaf-a75a-ef2650458d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ca0c8090ef7c>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/resnet34_shoplifting_aug_image1.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:\n",
            "Train Accuracy: 99.24%\n",
            "Test Accuracy:\n",
            "Test Accuracy: 97.20%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}